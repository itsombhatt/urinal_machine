{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3e90b3-a2f1-4e8c-b1ff-71b54a273272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Input\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, roc_curve, roc_auc_score, classification_report)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4616b662-707f-4cc9-9d7c-41218c57fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "#split into x and y sets\n",
    "X = data.drop(\"position\", axis=1).values\n",
    "y = data.position.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85c37166-b523-41ba-a6f6-78bd2b150b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.16, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15123e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({np.int64(0): 968,\n",
       "         np.int64(4): 949,\n",
       "         np.int64(2): 517,\n",
       "         np.int64(3): 414,\n",
       "         np.int64(1): 364})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(y)\n",
    "counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3532ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMetrics(model_name, pred):\n",
    "     print(f\"--- {model_name} ---\")\n",
    "     print(\"Test accuracy:\", accuracy_score(y_test, pred))\n",
    "     print(\"Precision:\", precision_score(y_test, pred, average='macro'))\n",
    "     print(\"Recall:\", recall_score(y_test, pred, average='macro'))\n",
    "     print(\"F1 Score:\", f1_score(y_test, pred, average='macro'))\n",
    "     print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, pred))\n",
    "     print(\"Classification Report:\\n\", classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d436f101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- decision tree ---\n",
      "Test accuracy: 0.669260700389105\n",
      "Precision: 0.6555978615978615\n",
      "Recall: 0.6121817543298747\n",
      "F1 Score: 0.6242729591620069\n",
      "Confusion Matrix:\n",
      " [[112   5   8   3  11]\n",
      " [ 14  24  10   0  13]\n",
      " [ 19   7  44  12  10]\n",
      " [  8   1   4  38  15]\n",
      " [ 15   0  12   3 126]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.81      0.73       139\n",
      "           1       0.65      0.39      0.49        61\n",
      "           2       0.56      0.48      0.52        92\n",
      "           3       0.68      0.58      0.62        66\n",
      "           4       0.72      0.81      0.76       156\n",
      "\n",
      "    accuracy                           0.67       514\n",
      "   macro avg       0.66      0.61      0.62       514\n",
      "weighted avg       0.66      0.67      0.66       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decisionTree = DecisionTreeClassifier(random_state=42)\n",
    "decisionTree.fit(X_train, y_train)\n",
    "predictions = decisionTree.predict(X_test)\n",
    "\n",
    "getMetrics(\"decision tree\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fb0c3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- bagged decision tree ---\n",
      "Test accuracy: 0.6653696498054474\n",
      "Precision: 0.6488206388206389\n",
      "Recall: 0.6103172441137849\n",
      "F1 Score: 0.6206538888036235\n",
      "Confusion Matrix:\n",
      " [[111   5   8   3  12]\n",
      " [ 14  24  10   0  13]\n",
      " [ 17   7  43  15  10]\n",
      " [  8   1   3  39  15]\n",
      " [ 15   0  13   3 125]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73       139\n",
      "           1       0.65      0.39      0.49        61\n",
      "           2       0.56      0.47      0.51        92\n",
      "           3       0.65      0.59      0.62        66\n",
      "           4       0.71      0.80      0.76       156\n",
      "\n",
      "    accuracy                           0.67       514\n",
      "   macro avg       0.65      0.61      0.62       514\n",
      "weighted avg       0.66      0.67      0.66       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bagged = BaggingClassifier(estimator=decisionTree, n_estimators=25, max_samples=1200, random_state=42)\n",
    "bagged.fit(X_train, y_train)\n",
    "predictions = bagged.predict(X_test)\n",
    "\n",
    "getMetrics(\"bagged decision tree\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2aab5844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- balance bagged decision tree ---\n",
      "Test accuracy: 0.6439688715953308\n",
      "Precision: 0.6162146379953776\n",
      "Recall: 0.617783990214086\n",
      "F1 Score: 0.611628165567496\n",
      "Confusion Matrix:\n",
      " [[ 88  20   7   7  17]\n",
      " [ 10  34   7   0  10]\n",
      " [ 11  15  41  11  14]\n",
      " [  4   4   2  43  13]\n",
      " [  4   3  12  12 125]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69       139\n",
      "           1       0.45      0.56      0.50        61\n",
      "           2       0.59      0.45      0.51        92\n",
      "           3       0.59      0.65      0.62        66\n",
      "           4       0.70      0.80      0.75       156\n",
      "\n",
      "    accuracy                           0.64       514\n",
      "   macro avg       0.62      0.62      0.61       514\n",
      "weighted avg       0.65      0.64      0.64       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "balbagged = BalancedBaggingClassifier(estimator=decisionTree, n_estimators=25, max_samples=100, random_state=42)\n",
    "balbagged.fit(X_train, y_train)\n",
    "predictions = balbagged.predict(X_test)\n",
    "\n",
    "getMetrics(\"balance bagged decision tree\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "440fa338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- random forest ---\n",
      "Test accuracy: 0.6517509727626459\n",
      "Precision: 0.6256746130362754\n",
      "Recall: 0.6387203049765801\n",
      "F1 Score: 0.6296813986794431\n",
      "Confusion Matrix:\n",
      " [[ 96  12  12  10   9]\n",
      " [  7  36   7   0  11]\n",
      " [ 12  11  45  17   7]\n",
      " [  5   1   3  47  10]\n",
      " [ 13   2  18  12 111]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71       139\n",
      "           1       0.58      0.59      0.59        61\n",
      "           2       0.53      0.49      0.51        92\n",
      "           3       0.55      0.71      0.62        66\n",
      "           4       0.75      0.71      0.73       156\n",
      "\n",
      "    accuracy                           0.65       514\n",
      "   macro avg       0.63      0.64      0.63       514\n",
      "weighted avg       0.66      0.65      0.65       514\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(n_estimators=100, # Number of trees to train\n",
    "                       criterion='gini', # How to train the trees. Also supports entropy.\n",
    "                       max_depth=None, # Max depth of the trees. Not necessary to change.\n",
    "                       min_samples_split=2, # Minimum samples to create a split.\n",
    "                       min_samples_leaf=0.001, # Minimum samples in a leaf. Accepts fractions for %. This is 0.1% of sample.\n",
    "                       min_weight_fraction_leaf=0.0, # Same as above, but uses the class weights.\n",
    "                       max_features='sqrt', # Maximum number of features per split (not tree!) by default is sqrt(vars)\n",
    "                       max_leaf_nodes=None, # Maximum number of nodes.\n",
    "                       min_impurity_decrease=0.0001, # Minimum impurity decrease. This is 10^-3.\n",
    "                       bootstrap=True, # If sample with repetition. For large samples (>100.000) set to false.\n",
    "                       oob_score=True,  # If report accuracy with non-selected cases.\n",
    "                    #    n_jobs=-1, # Parallel processing. Set to -1 for all cores. Watch your RAM!!\n",
    "                       random_state=42, # Seed\n",
    "                       verbose=1, # If to give info during training. Set to 0 for silent training.\n",
    "                       warm_start=False, # If train over previously trained tree.\n",
    "                       class_weight='balanced'\n",
    "                                    )\n",
    "randomForest.fit(X_train, y_train)\n",
    "\n",
    "predictions = randomForest.predict(X_test)\n",
    "\n",
    "getMetrics(\"random forest\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d001d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- gradient boosting ---\n",
      "Test accuracy: 0.6867704280155642\n",
      "Precision: 0.7031314805371409\n",
      "Recall: 0.6188715500542161\n",
      "F1 Score: 0.6400673765417146\n",
      "Confusion Matrix:\n",
      " [[110   0   7   2  20]\n",
      " [ 17  27   3   1  13]\n",
      " [ 17   7  42   8  18]\n",
      " [  8   2   3  33  20]\n",
      " [  8   1   5   1 141]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       139\n",
      "           1       0.73      0.44      0.55        61\n",
      "           2       0.70      0.46      0.55        92\n",
      "           3       0.73      0.50      0.59        66\n",
      "           4       0.67      0.90      0.77       156\n",
      "\n",
      "    accuracy                           0.69       514\n",
      "   macro avg       0.70      0.62      0.64       514\n",
      "weighted avg       0.69      0.69      0.67       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradient = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "gradient.fit(X_train, y_train)\n",
    "\n",
    "predictions = gradient.predict(X_test)\n",
    "\n",
    "getMetrics(\"gradient boosting\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23e0600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- logistic regression ---\n",
      "Test accuracy: 0.6789883268482491\n",
      "Precision: 0.7017159892268148\n",
      "Recall: 0.6213798281861579\n",
      "F1 Score: 0.6422622452343815\n",
      "Confusion Matrix:\n",
      " [[110   1   3   4  21]\n",
      " [ 15  26   2   1  17]\n",
      " [ 17   6  43   8  18]\n",
      " [  5   0   3  38  20]\n",
      " [ 10   1  10   3 132]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74       139\n",
      "           1       0.76      0.43      0.55        61\n",
      "           2       0.70      0.47      0.56        92\n",
      "           3       0.70      0.58      0.63        66\n",
      "           4       0.63      0.85      0.73       156\n",
      "\n",
      "    accuracy                           0.68       514\n",
      "   macro avg       0.70      0.62      0.64       514\n",
      "weighted avg       0.69      0.68      0.67       514\n",
      "\n",
      "--- bagged logistic regression ---\n",
      "Test accuracy: 0.6789883268482491\n",
      "Precision: 0.7014726312975574\n",
      "Recall: 0.6215366258249699\n",
      "F1 Score: 0.6423033213368614\n",
      "Confusion Matrix:\n",
      " [[111   1   3   4  20]\n",
      " [ 15  26   2   1  17]\n",
      " [ 17   6  43   8  18]\n",
      " [  5   0   3  38  20]\n",
      " [ 11   1  10   3 131]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74       139\n",
      "           1       0.76      0.43      0.55        61\n",
      "           2       0.70      0.47      0.56        92\n",
      "           3       0.70      0.58      0.63        66\n",
      "           4       0.64      0.84      0.72       156\n",
      "\n",
      "    accuracy                           0.68       514\n",
      "   macro avg       0.70      0.62      0.64       514\n",
      "weighted avg       0.69      0.68      0.67       514\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(penalty='l2', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "getMetrics(\"logistic regression\", predictions)\n",
    "\n",
    "bagged = BaggingClassifier(estimator=model, n_estimators=50, random_state=42)\n",
    "bagged.fit(X_train, y_train)\n",
    "\n",
    "predictions = bagged.predict(X_test)\n",
    "\n",
    "getMetrics(\"bagged logistic regression\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a5551d-d1ed-4aef-af7b-899d1e4b0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sequential model object\n",
    "model = Sequential()\n",
    "#add an input layer specifying 10 units and a sigmoid activation function\n",
    "#note: input shape must be specified on the first layer and should be equal to the number of features\n",
    "model.add(Dense(5, input_shape=(X_train_scaled.shape[1],), activation = 'sigmoid'))\n",
    "#add a hidden layer with 5 units and a sigmoid activation function\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "#add an output layer with 3 hidden units, one for each of the possible predictions with a sigmoid activation\n",
    "model.add(Dense(5, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de2c83-8e67-410a-8dd8-96d071b364e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
